---
title: "Machine Learning algorithm - Predictive modeling for barbell lifts"
author: "Edward Lewis"
date: "April 24, 2015"
output: html_document
---

## Executive Summary
The goal of this predictive model is to use data from personal activity devices' accelerometers on the belt, forearm, arm, and dumbell of 6 participants to determine the classe of the barbell lift they performed.  The participants performed barbell lifts correctly and incorrectly in 5 different ways (A, B, C, D, E).   The overall predictive model chosen has an accuracy rate of 99.3% and an out of sample error to be 0.7%

## Exploratory Data Analysis
Load libraries needed for this effort and initial datasets to data.frames

The data for this project come from this source: ```http://groupware.les.inf.puc-rio.br/har```

```{r}
## Practical Machine Learning
suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(rattle))
suppressMessages(library(randomForest))
suppressMessages(library(knitr))
suppressMessages(library(gbm))
suppressMessages(library(rpart))

## The training data for this project are available here: 
TRAINFILE <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

## The test data are available here:         
TESTFILE <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if(!file.exists("./pml-training.csv")) { download.file(TRAINFILE, destfile="./pml-training.csv", method="curl") }
if(!file.exists("./pml-testing.csv")) { download.file(TESTFILE, destfile="./pml-testing.csv", method="curl") }

## Read in data to dataframes
pml_training <- read.csv("./pml-training.csv")
pml_testing <- read.csv("./pml-testing.csv")

```

Split the training dataset into a training and testing dataset so we can use the training subset to build a predictive model and do some validation on the new testing subset
  
```{r}
## create training and testing subset from pml_training data
set.seed(33234)
inTrain = createDataPartition(y=pml_training$classe,p=0.7, list=FALSE)
training <- pml_training[inTrain,]
testing <- pml_training[-inTrain,]
```
  
Now lets look at some of the overall data in the new training dataset.
```{r}
## look at sample data and structure of data
head(training)
str(training)
colnames(training)

```
  
   
From this we want to subset the training dataset to only those columns that have data related to the accelerometers    
```{r}
## Get accelerometers data only
## columns we want to keep begin with roll_, pitch_, yaw_ total_accel_, gyros, accel_
keep_cols <- c("^roll_","^pitch_","^yaw_","^total_accel_","^gyros_","^accel_","^magnet_")

df_index <- unique(grep(paste(keep_cols,collapse="|"),colnames(training)))

## add the classe column (160) to the index of accelerometers.  Just want to keep those columns
df_index <- c(df_index, 160)

training <- subset(training[df_index],)


```
  
  
We can visualize a few of the columns of data and the various "classe" types.
```{r}
featurePlot(x=training[,c("yaw_arm","pitch_arm","roll_arm","gyros_arm_x","magnet_arm_x","total_accel_arm")], y=training$classe,plot="strip", jitter=TRUE, colour=training$classe)
```

## Building Predictive Model
  
Lets initially try a tree based model
```{r , cache=TRUE}
set.seed(33234)
modFitA <- train(classe ~ . , method="rpart", data=training)
```

Here we can visualize the tree
```{r}
fancyRpartPlot(modFitA$finalModel)
```

And we can look at the overall details about the model.
```{r}
modFitA
```
From this we can see that the overall accuracy is relatively poor at 50.45%
  
If we look at the confusion matrix against the testing dataset we can see a significant number of activities were mis-classified.  The accuracy was just 50.33%

```{r}
predictions <- predict(modFitA, newdata=testing)
confusionMatrix(predictions, testing$classe)
```


So lets look for a better model.  Next try is generalized Boosting model
```{r , cache=TRUE}
set.seed(33234)
modFitB <- train(classe ~ . , data=training, method="gbm", verbose=FALSE)
modFitB
```

Lets look at a confusion Matrix against the testing dataset.  Here we can see this is a much better model with a 95.99% accuracy rate.   Better, but lets see if we can still find a better prediction model.

```{r}
predictions <- predict(modFitB, newdata=testing)
confusionMatrix(predictions, testing$classe)
```

  
  
Lets try a Random Forest model with cross-validation.  
```{r , cache=TRUE}
set.seed(33234)
fitControl <- trainControl(method="cv")
modFitC <- train(classe ~ . , data = training, method="rf" , trControl = fitControl)
modFitC

```

Here we can see the overall accuracy is approx 99.3% .   The out of sample error is (1-accuracy = 0.7%) .  The accuracy is generally good and this is the model I will use for the real testing dataset.  
```{r}
predictions <- predict(modFitC, newdata=testing)
confusionMatrix(predictions, testing$classe)
```

We can look at which Variables were the most important in determining the answers
```{r}
varImp(modFitC)
```

## FINAL CONCLUSION
The Random Forest model (modFitC) is the chosen model to use for prediciton.  It had a 99.3% accuracy rate.   This will be used against the testing dataset for submission.






